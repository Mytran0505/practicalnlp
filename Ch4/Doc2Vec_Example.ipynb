{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec demonstration \n",
    "\n",
    "In this notebook, let us take a look at how to \"learn\" document embeddings and use them for text classification. We will be using the dataset of \"Sentiment and Emotion in Text\" from Figure-Eight.\n",
    "\n",
    "\"In a variation on the popular task of sentiment analysis, this dataset contains labels for the emotional content (such as happiness, sadness, and anger) of texts. Hundreds to thousands of examples across 13 labels. A subset of this data is used in an experiment we uploaded to Microsoftâ€™s Cortana Intelligence Gallery.\"\n",
    "\n",
    "###https://www.figure-eight.com/data-for-everyone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset and explore.\n",
    "filepath = \"/home/bangaru/Downloads/NLPBookTut/text_emotion.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22306, 4)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us take the top 4 categories and leave out the rest.\n",
    "shortlist = ['neutral', \"happiness\", \"worry\"]\n",
    "df_subset = df[df['sentiment'].isin(shortlist)]\n",
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Text pre-processing:\n",
    "- Removing @mentions, and urls perhaps?\n",
    "- using NLTK Tweet tokenizer instead of a regular one\n",
    "- may be just take: happiness, sadness, worry, neutral and ignore other cats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22306 22306\n"
     ]
    }
   ],
   "source": [
    "tweeter = TweetTokenizer(strip_handles=True,preserve_case=False)\n",
    "mystopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_corpus(texts):\n",
    "    def remove_stops_digits(tokens):\n",
    "        #Nested function that removes stopwords and digits from a list of tokens\n",
    "        return [token for token in tokens if token not in mystopwords and not token.isdigit()]\n",
    "    #This return statement below uses the above function to process twitter tokenizer output further. \n",
    "    return [remove_stops_digits(tweeter.tokenize(content)) for content in texts]\n",
    "\n",
    "\n",
    "mydata = preprocess_corpus(df_subset['content'])\n",
    "mycats = df_subset['sentiment']\n",
    "print(len(mydata), len(mycats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test\n",
    "train_data, test_data, train_cats, test_cats = train_test_split(mydata,mycats,random_state=1234)\n",
    "\n",
    "#prepare training data in doc2vec format:\n",
    "train_doc2vec = [TaggedDocument((d), tags=[str(i)]) for i, d in enumerate(train_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#Train a doc2vec model\n",
    "max_epochs = 100\n",
    "vec_size = 50\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_count=10,\n",
    "                dm =1, epochs=max_epochs)\n",
    "  \n",
    "model.build_vocab(train_doc2vec)\n",
    "print(model.epochs)\n",
    "\n",
    "model.train(train_doc2vec,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infer using that model\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "train_vectors =  [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in train_data]\n",
    "test_vectors = [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happiness' 'neutral' 'worry']\n"
     ]
    }
   ],
   "source": [
    "#Use any regular classifier like logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "myclass = LogisticRegression(class_weight=\"balanced\")\n",
    "myclass.fit(train_vectors, train_cats)\n",
    "print(myclass.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  happiness       0.50      0.47      0.49      1331\n",
      "    neutral       0.47      0.58      0.52      2143\n",
      "      worry       0.54      0.44      0.49      2103\n",
      "\n",
      "avg / total       0.51      0.50      0.50      5577\n",
      "\n",
      "[[ 626  498  207]\n",
      " [ 328 1245  570]\n",
      " [ 290  889  924]]\n"
     ]
    }
   ],
   "source": [
    "preds = myclass.predict(test_vectors)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(test_cats, preds))\n",
    "print(confusion_matrix(test_cats,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
